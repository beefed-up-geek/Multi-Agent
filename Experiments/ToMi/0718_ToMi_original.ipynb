{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d582815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "#os.environ['OPENAI_API_KEY'] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f26261",
   "metadata": {},
   "source": [
    "## 1. Agent 설정\n",
    "LLM, Temperature, 프롬프트, 페르소나 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef47ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    request_timeout=60,\n",
    "                    api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "system_prompt = '''Y\n",
    "You are a logical reasoning assistant.  \n",
    "You will be shown a short story as a list of sentences and then a question.  \n",
    "Your task is to answer using exactly one English word naming a location (e.g., “desk”, “bookshelf”).  \n",
    "Do not add any extra words, punctuation, or explanation—just the single location word.\n",
    "'''\n",
    "\n",
    "integrated_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt.strip()),\n",
    "    (\"human\", \"\"\"\n",
    "[Story]\n",
    "{Story}\n",
    "\n",
    "[Question]\n",
    "{Question}\n",
    "\n",
    "\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17556a",
   "metadata": {},
   "source": [
    "## 2. 질문 하나만 테스트 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be4725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = '''\n",
    "1. Oliver entered the porch.\n",
    "2. Owen entered the porch.\n",
    "3. Abigail entered the porch.\n",
    "4. The broccoli is in the bucket.\n",
    "5. Abigail exited the porch.\n",
    "6. Owen exited the porch.\n",
    "7. Owen hates the peach\n",
    "8. Oliver moved the broccoli to the pantry.\n",
    "'''\n",
    "qa_list = [\n",
    "    {'type': 'reality', 'question':'Where is the broccoli really?', 'answer':'pantry'},\n",
    "    {'type':'memory', 'question':'Where was the broccoli at the beginning?', 'answer':'bucket'},\n",
    "    {'type':'first_order', 'question':'Where will Oliver look for the broccoli?', 'answer':'pantry'},\n",
    "    {'type':'first_order', 'question':'Where will Abigail look for the broccoli?', 'answer':'bucket'},\n",
    "    {'type':'second_order', 'question':'Where does Oliver think that Abigail searches for the broccoli?', 'answer':'pantry'},\n",
    "    {'type':'second_order', 'question':'Where does Abigail think that Oliver searches for the broccoli?', 'answer':'pantry'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a6737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mQuestion 1 (reality): )Where is the broccoli really?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 2 (memory): )Where was the broccoli at the beginning?\u001b[0m\n",
      "  Model answer: bucket, Correct answer: bucket\n",
      "\u001b[94mQuestion 3 (first_order): )Where will Oliver look for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 4 (first_order): )Where will Abigail look for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: bucket\n",
      "\u001b[94mQuestion 5 (second_order): )Where does Oliver think that Abigail searches for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 6 (second_order): )Where does Abigail think that Oliver searches for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n"
     ]
    }
   ],
   "source": [
    "for i, qa in enumerate(qa_list, 1):\n",
    "    response = llm.invoke(integrated_prompt.format_messages(\n",
    "        Story=story.strip(), Question=qa['question']\n",
    "    ))\n",
    "    answer = response.content.strip()\n",
    "    print(f\"\\033[94mQuestion {i} ({qa['type']}): ){qa['question']}\\033[0m\")\n",
    "    print(f\"  Model answer: {answer}, Correct answer: {qa['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a9081",
   "metadata": {},
   "source": [
    "## 3. 전체 데이터셋에 실험 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 100 stories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# GitHub raw CSV URL\n",
    "url = \"https://raw.githubusercontent.com/beefed-up-geek/Multi-Agent/main/Experiments/ToMi/ToMi_official_github/tomi_dataset.csv\"\n",
    "\n",
    "# 상위 100개 story 불러오기\n",
    "df = pd.read_csv(url)\n",
    "df_top100 = df.head(100)\n",
    "\n",
    "print(\"Loaded dataset with\", len(df_top100), \"stories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2577a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stories: 100%|██████████| 100/100 [06:55<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\n",
      "Reality     : 96/100 = 96.00%\n",
      "Memory      : 100/100 = 100.00%\n",
      "First order : 161/200 = 80.50%\n",
      "Second order: 109/200 = 54.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm                     # ← NEW: progress-bar utility\n",
    "\n",
    "correct = {\"Reality\": 0, \"Memory\": 0,\n",
    "           \"First order\": 0, \"Second order\": 0}\n",
    "total   = {\"Reality\": 0, \"Memory\": 0,\n",
    "           \"First order\": 0, \"Second order\": 0}\n",
    "\n",
    "# tqdm shows progress & ETA\n",
    "for _, row in tqdm(df_top100.iterrows(), total=len(df_top100), desc=\"Stories\"):\n",
    "    story = row[\"Story\"]\n",
    "\n",
    "    for q_col, a_col in [(\"Reality Question\", \"Reality Answer\")]:\n",
    "        total[\"Reality\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Reality\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"Memory Question\", \"Memory Answer\")]:\n",
    "        total[\"Memory\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Memory\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"First-Order Belief A Question\", \"First-Order Belief A Answer\"),\n",
    "                         (\"First-Order Belief B Question\", \"First-Order Belief B Answer\")]:\n",
    "        total[\"First order\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"First order\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"Second-Order Belief A Question\", \"Second-Order Belief A Answer\"),\n",
    "                         (\"Second-Order Belief B Question\", \"Second-Order Belief B Answer\")]:\n",
    "        total[\"Second order\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Second order\"] += 1\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "for cat in [\"Reality\", \"Memory\", \"First order\", \"Second order\"]:\n",
    "    pct = correct[cat] / total[cat] * 100 if total[cat] else 0.0\n",
    "    print(f\"{cat:12}: {correct[cat]}/{total[cat]} = {pct:5.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
