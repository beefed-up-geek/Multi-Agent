{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d582815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "#os.environ['OPENAI_API_KEY'] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f26261",
   "metadata": {},
   "source": [
    "## 1. Agent 설정\n",
    "LLM, Temperature, 프롬프트, 페르소나 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef47ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    request_timeout=60,\n",
    "                    api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "system_prompt = '''Y\n",
    "You are a three-year-old child playing with your friends and toys.\n",
    "You will be shown a short story about a pretend play you are doing as a list of sentences and then a question.  \n",
    "Your task is to answer using exactly one English word naming a location (e.g., “desk”, “bookshelf”).  \n",
    "Do not add any extra words, punctuation, or explanation—just the single location word.\n",
    "'''\n",
    "\n",
    "integrated_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt.strip()),\n",
    "    (\"human\", \"\"\"\n",
    "[Story]\n",
    "{Story}\n",
    "\n",
    "[Question]\n",
    "{Question}\n",
    "\n",
    "\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17556a",
   "metadata": {},
   "source": [
    "## 2. 질문 하나만 테스트 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "story = '''\n",
    "1. Logan loves the beans\n",
    "2. Ethan entered the office.\n",
    "3. Toy robot with painted face entered the pantry.\n",
    "4. Logan entered the pantry.\n",
    "5. The pineapple is in the drawer.\n",
    "6. Toy robot with painted face moved the pineapple to the bathtub.\n",
    "7. Logan exited the pantry.\n",
    "8. Ethan dislikes the tangerine\n",
    "9. Toy robot with painted face exited the pantry.\n",
    "10. Logan entered the pantry.\n",
    "'''\n",
    "qa_list = [\n",
    "    {'type': 'reality', 'question':'Where is the pineapple really?', 'answer':'bathtub'},\n",
    "    {'type':'memory', 'question':'Where was the pineapple at the beginning?', 'answer':'drawer'},\n",
    "    {'type':'first_order', 'question':'Where will Toy robot with painted face look for the pineapple?', 'answer':'bathtub'},\n",
    "    {'type':'first_order', 'question':'Where will Logan look for the pineapple?', 'answer':'bathtub'},\n",
    "    {'type':'second_order', 'question':'Where does Toy robot with painted face think that Logan searches for the pineapple?', 'answer':'bathtub'},\n",
    "    {'type':'second_order', 'question':'Where does Logan think that Toy robot with painted face searches for the pineapple?', 'answer':'bathtub'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a6737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mQuestion 1 (reality): )Where is the broccoli really?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 2 (memory): )Where was the broccoli at the beginning?\u001b[0m\n",
      "  Model answer: bucket, Correct answer: bucket\n",
      "\u001b[94mQuestion 3 (first_order): )Where will Oliver look for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 4 (first_order): )Where will Abigail look for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: bucket\n",
      "\u001b[94mQuestion 5 (second_order): )Where does Oliver think that Abigail searches for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n",
      "\u001b[94mQuestion 6 (second_order): )Where does Abigail think that Oliver searches for the broccoli?\u001b[0m\n",
      "  Model answer: pantry, Correct answer: pantry\n"
     ]
    }
   ],
   "source": [
    "for i, qa in enumerate(qa_list, 1):\n",
    "    response = llm.invoke(integrated_prompt.format_messages(\n",
    "        Story=story.strip(), Question=qa['question']\n",
    "    ))\n",
    "    answer = response.content.strip()\n",
    "    print(f\"\\033[94mQuestion {i} ({qa['type']}): ){qa['question']}\\033[0m\")\n",
    "    print(f\"  Model answer: {answer}, Correct answer: {qa['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a9081",
   "metadata": {},
   "source": [
    "## 3. 전체 데이터셋에 실험 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e76f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 100 stories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# GitHub raw CSV URL\n",
    "url = \"https://raw.githubusercontent.com/beefed-up-geek/Multi-Agent/main/Experiments/ToMi/ToMi_github/tomi_dataset.csv\"\n",
    "\n",
    "# 상위 100개 story 불러오기\n",
    "df = pd.read_csv(url)\n",
    "df_top100 = df.head(100)\n",
    "\n",
    "print(\"Loaded dataset with\", len(df_top100), \"stories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2577a1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stories: 100%|██████████| 100/100 [06:55<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy\n",
      "Reality     : 96/100 = 96.00%\n",
      "Memory      : 100/100 = 100.00%\n",
      "First order : 161/200 = 80.50%\n",
      "Second order: 109/200 = 54.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm                     # ← NEW: progress-bar utility\n",
    "\n",
    "correct = {\"Reality\": 0, \"Memory\": 0,\n",
    "           \"First order\": 0, \"Second order\": 0}\n",
    "total   = {\"Reality\": 0, \"Memory\": 0,\n",
    "           \"First order\": 0, \"Second order\": 0}\n",
    "\n",
    "# tqdm shows progress & ETA\n",
    "for _, row in tqdm(df_top100.iterrows(), total=len(df_top100), desc=\"Stories\"):\n",
    "    story = row[\"Story\"]\n",
    "\n",
    "    for q_col, a_col in [(\"Reality Question\", \"Reality Answer\")]:\n",
    "        total[\"Reality\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Reality\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"Memory Question\", \"Memory Answer\")]:\n",
    "        total[\"Memory\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Memory\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"First-Order Belief A Question\", \"First-Order Belief A Answer\"),\n",
    "                         (\"First-Order Belief B Question\", \"First-Order Belief B Answer\")]:\n",
    "        total[\"First order\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"First order\"] += 1\n",
    "\n",
    "    for q_col, a_col in [(\"Second-Order Belief A Question\", \"Second-Order Belief A Answer\"),\n",
    "                         (\"Second-Order Belief B Question\", \"Second-Order Belief B Answer\")]:\n",
    "        total[\"Second order\"] += 1\n",
    "        pred = llm.invoke(\n",
    "            integrated_prompt.format_messages(Story=story, Question=row[q_col])\n",
    "        ).content.strip().lower()\n",
    "        if pred == row[a_col].strip().lower():\n",
    "            correct[\"Second order\"] += 1\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "for cat in [\"Reality\", \"Memory\", \"First order\", \"Second order\"]:\n",
    "    pct = correct[cat] / total[cat] * 100 if total[cat] else 0.0\n",
    "    print(f\"{cat:12}: {correct[cat]}/{total[cat]} = {pct:5.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
